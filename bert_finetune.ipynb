{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  4 16:20:14 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   38C    P8    23W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>text</th>\n",
       "      <th>icu_death</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17915608-RR-64</td>\n",
       "      <td>20008098</td>\n",
       "      <td>RR</td>\n",
       "      <td>64</td>\n",
       "      <td>1975-02-06 16:23:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17915608-RR-65</td>\n",
       "      <td>20008098</td>\n",
       "      <td>RR</td>\n",
       "      <td>65</td>\n",
       "      <td>1975-02-07 10:50:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17915608-RR-66</td>\n",
       "      <td>20008098</td>\n",
       "      <td>RR</td>\n",
       "      <td>66</td>\n",
       "      <td>1975-02-07 20:17:00</td>\n",
       "      <td>INDICATION:  ___ year old man s/p RUL lobectom...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17915608-RR-67</td>\n",
       "      <td>20008098</td>\n",
       "      <td>RR</td>\n",
       "      <td>67</td>\n",
       "      <td>1975-02-08 12:20:00</td>\n",
       "      <td>INDICATION:  ___ year old man s/p VATS to Open...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17915608-RR-68</td>\n",
       "      <td>20008098</td>\n",
       "      <td>RR</td>\n",
       "      <td>68</td>\n",
       "      <td>1975-02-09 07:26:00</td>\n",
       "      <td>INDICATION:  ___ year old man s/p open RUL lob...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id        id note_type  note_seq            charttime  \\\n",
       "0  17915608-RR-64  20008098        RR        64  1975-02-06 16:23:00   \n",
       "1  17915608-RR-65  20008098        RR        65  1975-02-07 10:50:00   \n",
       "2  17915608-RR-66  20008098        RR        66  1975-02-07 20:17:00   \n",
       "3  17915608-RR-67  20008098        RR        67  1975-02-08 12:20:00   \n",
       "4  17915608-RR-68  20008098        RR        68  1975-02-09 07:26:00   \n",
       "\n",
       "                                                text  icu_death  interval  \n",
       "0  EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...          0         3  \n",
       "1  EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...          0         2  \n",
       "2  INDICATION:  ___ year old man s/p RUL lobectom...          0         2  \n",
       "3  INDICATION:  ___ year old man s/p VATS to Open...          0         1  \n",
       "4  INDICATION:  ___ year old man s/p open RUL lob...          0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = pd.read_csv('data/notes_with_interval.csv')\n",
    "\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>text</th>\n",
       "      <th>icu_death</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>10007818-RR-10</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>10</td>\n",
       "      <td>2046-06-11 08:38:00</td>\n",
       "      <td>EXAMINATION:  DUPLEX DOPP ABD/PEL\\n\\nINDICATIO...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>10007818-RR-11</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>11</td>\n",
       "      <td>2046-06-11 14:46:00</td>\n",
       "      <td>EXAMINATION:  Ultrasound-guided paracentesis\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>10007818-RR-12</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>12</td>\n",
       "      <td>2046-06-11 17:29:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>10007818-RR-13</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>13</td>\n",
       "      <td>2046-06-13 14:27:00</td>\n",
       "      <td>EXAMINATION:  Ultrasound-guided paracentesis\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>10007818-RR-14</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>14</td>\n",
       "      <td>2046-06-15 16:42:00</td>\n",
       "      <td>EXAMINATION:  RENAL U.S.\\n\\nINDICATION:  ___ y...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>10007818-RR-15</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>15</td>\n",
       "      <td>2046-06-17 15:24:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>10007818-RR-16</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>16</td>\n",
       "      <td>2046-06-17 20:13:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>10007818-RR-17</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>17</td>\n",
       "      <td>2046-06-19 13:55:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>10007818-RR-18</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>18</td>\n",
       "      <td>2046-06-19 12:38:00</td>\n",
       "      <td>EXAMINATION:  US Interventional Procedure\\n\\nI...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>10007818-RR-19</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>19</td>\n",
       "      <td>2046-06-20 11:58:00</td>\n",
       "      <td>INDICATION:  ___ year old man with cirrhosis, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>10007818-RR-20</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>20</td>\n",
       "      <td>2046-06-22 14:55:00</td>\n",
       "      <td>EXAMINATION:  CTA ABD AND PELVIS\\n\\nINDICATION...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>10007818-RR-21</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>21</td>\n",
       "      <td>2046-06-22 15:49:00</td>\n",
       "      <td>INDICATION:  ___ year old man with RP bleed, o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>10007818-RR-22</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>22</td>\n",
       "      <td>2046-06-22 22:17:00</td>\n",
       "      <td>EXAMINATION:  CHEST PORT. LINE PLACEMENT\\n\\nIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812</th>\n",
       "      <td>10007818-RR-23</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>23</td>\n",
       "      <td>2046-06-23 08:02:00</td>\n",
       "      <td>EXAMINATION:  CT abdomen/pelvis.\\n\\nINDICATION...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>10007818-RR-24</td>\n",
       "      <td>22987108</td>\n",
       "      <td>RR</td>\n",
       "      <td>24</td>\n",
       "      <td>2046-06-23 08:12:00</td>\n",
       "      <td>INDICATION:  ___ year old man with left groin ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             note_id        id note_type  note_seq            charttime  \\\n",
       "6799  10007818-RR-10  22987108        RR        10  2046-06-11 08:38:00   \n",
       "6800  10007818-RR-11  22987108        RR        11  2046-06-11 14:46:00   \n",
       "6801  10007818-RR-12  22987108        RR        12  2046-06-11 17:29:00   \n",
       "6802  10007818-RR-13  22987108        RR        13  2046-06-13 14:27:00   \n",
       "6803  10007818-RR-14  22987108        RR        14  2046-06-15 16:42:00   \n",
       "6804  10007818-RR-15  22987108        RR        15  2046-06-17 15:24:00   \n",
       "6805  10007818-RR-16  22987108        RR        16  2046-06-17 20:13:00   \n",
       "6806  10007818-RR-17  22987108        RR        17  2046-06-19 13:55:00   \n",
       "6807  10007818-RR-18  22987108        RR        18  2046-06-19 12:38:00   \n",
       "6808  10007818-RR-19  22987108        RR        19  2046-06-20 11:58:00   \n",
       "6809  10007818-RR-20  22987108        RR        20  2046-06-22 14:55:00   \n",
       "6810  10007818-RR-21  22987108        RR        21  2046-06-22 15:49:00   \n",
       "6811  10007818-RR-22  22987108        RR        22  2046-06-22 22:17:00   \n",
       "6812  10007818-RR-23  22987108        RR        23  2046-06-23 08:02:00   \n",
       "6813  10007818-RR-24  22987108        RR        24  2046-06-23 08:12:00   \n",
       "\n",
       "                                                   text  icu_death  interval  \n",
       "6799  EXAMINATION:  DUPLEX DOPP ABD/PEL\\n\\nINDICATIO...          1        11  \n",
       "6800  EXAMINATION:  Ultrasound-guided paracentesis\\n...          1        11  \n",
       "6801  EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...          1        11  \n",
       "6802  EXAMINATION:  Ultrasound-guided paracentesis\\n...          1         9  \n",
       "6803  EXAMINATION:  RENAL U.S.\\n\\nINDICATION:  ___ y...          1         7  \n",
       "6804  EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...          1         5  \n",
       "6805  EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATIO...          1         5  \n",
       "6806  EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...          1         3  \n",
       "6807  EXAMINATION:  US Interventional Procedure\\n\\nI...          1         3  \n",
       "6808  INDICATION:  ___ year old man with cirrhosis, ...          1         2  \n",
       "6809  EXAMINATION:  CTA ABD AND PELVIS\\n\\nINDICATION...          1         0  \n",
       "6810  INDICATION:  ___ year old man with RP bleed, o...          1         0  \n",
       "6811  EXAMINATION:  CHEST PORT. LINE PLACEMENT\\n\\nIN...          1         0  \n",
       "6812  EXAMINATION:  CT abdomen/pelvis.\\n\\nINDICATION...          1         0  \n",
       "6813  INDICATION:  ___ year old man with left groin ...          1         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes[notes['id'] == 22987108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hosp_admittime</th>\n",
       "      <th>hosp_dischtime</th>\n",
       "      <th>icu_intime</th>\n",
       "      <th>icu_outtime</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>icu_death</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>...</th>\n",
       "      <th>atrial_fibrillation</th>\n",
       "      <th>malignant_cancer</th>\n",
       "      <th>chf</th>\n",
       "      <th>ckd</th>\n",
       "      <th>cld</th>\n",
       "      <th>copd</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>ihd</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21999692</td>\n",
       "      <td>2/20/77 21:08</td>\n",
       "      <td>3/6/77 16:40</td>\n",
       "      <td>2/22/77 16:35</td>\n",
       "      <td>2/25/77 17:54</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>55.139306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25936663</td>\n",
       "      <td>1/11/45 23:02</td>\n",
       "      <td>1/22/45 16:06</td>\n",
       "      <td>1/12/45 15:10</td>\n",
       "      <td>1/13/45 18:50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>65.032170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25675339</td>\n",
       "      <td>11/2/83 21:12</td>\n",
       "      <td>11/19/83 15:36</td>\n",
       "      <td>11/6/83 20:59</td>\n",
       "      <td>11/10/83 0:44</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>61.837481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27993048</td>\n",
       "      <td>11/19/67 8:23</td>\n",
       "      <td>12/25/67 14:53</td>\n",
       "      <td>11/26/67 16:26</td>\n",
       "      <td>12/5/67 16:53</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>56.881238</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>22987108</td>\n",
       "      <td>6/10/46 16:37</td>\n",
       "      <td>7/12/46 0:00</td>\n",
       "      <td>6/22/46 11:46</td>\n",
       "      <td>7/13/46 0:27</td>\n",
       "      <td>20.53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>69.439961</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id hosp_admittime  hosp_dischtime      icu_intime    icu_outtime  \\\n",
       "11  21999692  2/20/77 21:08    3/6/77 16:40   2/22/77 16:35  2/25/77 17:54   \n",
       "22  25936663  1/11/45 23:02   1/22/45 16:06   1/12/45 15:10  1/13/45 18:50   \n",
       "25  25675339  11/2/83 21:12  11/19/83 15:36   11/6/83 20:59  11/10/83 0:44   \n",
       "30  27993048  11/19/67 8:23  12/25/67 14:53  11/26/67 16:26  12/5/67 16:53   \n",
       "32  22987108  6/10/46 16:37    7/12/46 0:00   6/22/46 11:46   7/13/46 0:27   \n",
       "\n",
       "    los_icu  icu_death  gender                    race  admission_age  ...  \\\n",
       "11     3.05          0       1  BLACK/AFRICAN AMERICAN      55.139306  ...   \n",
       "22     1.15          0       1                   WHITE      65.032170  ...   \n",
       "25     3.16          0       1                   WHITE      61.837481  ...   \n",
       "30     9.02          0       0                   WHITE      56.881238  ...   \n",
       "32    20.53          1       1                   WHITE      69.439961  ...   \n",
       "\n",
       "    atrial_fibrillation  malignant_cancer chf ckd  cld  copd  diabetes  \\\n",
       "11                    0                 0   0   0    0     1         0   \n",
       "22                    0                 1   0   0    1     0         0   \n",
       "25                    0                 0   0   0    0     0         0   \n",
       "30                    0                 0   1   1    0     0         1   \n",
       "32                    1                 0   0   1    0     0         0   \n",
       "\n",
       "    hypertension  ihd  stroke  \n",
       "11             0    0       0  \n",
       "22             1    1       0  \n",
       "25             0    0       0  \n",
       "30             1    1       0  \n",
       "32             1    1       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static = pd.read_csv('data/static.csv')\n",
    "static = static[static['id'].isin(notes['id'])]\n",
    "\n",
    "static['gender'] = static['gender'].map(lambda x: 1 if x == 'M' else 0).astype(int)\n",
    "static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "hosp_admittime            0\n",
       "hosp_dischtime            0\n",
       "icu_intime                0\n",
       "icu_outtime               0\n",
       "los_icu                   0\n",
       "icu_death                 0\n",
       "gender                    0\n",
       "race                      0\n",
       "admission_age             0\n",
       "weight_admit            125\n",
       "height                 1381\n",
       "admission_type            0\n",
       "first_careunit            0\n",
       "charlson_score            0\n",
       "atrial_fibrillation       0\n",
       "malignant_cancer          0\n",
       "chf                       0\n",
       "ckd                       0\n",
       "cld                       0\n",
       "copd                      0\n",
       "diabetes                  0\n",
       "hypertension              0\n",
       "ihd                       0\n",
       "stroke                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>icu_death</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>height</th>\n",
       "      <th>charlson_score</th>\n",
       "      <th>atrial_fibrillation</th>\n",
       "      <th>malignant_cancer</th>\n",
       "      <th>chf</th>\n",
       "      <th>ckd</th>\n",
       "      <th>cld</th>\n",
       "      <th>copd</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>ihd</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21999692.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.139306</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25936663.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.032170</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25675339.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.837481</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>159.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27993048.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.881238</td>\n",
       "      <td>78.366667</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>22987108.0</td>\n",
       "      <td>20.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.439961</td>\n",
       "      <td>86.200000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  los_icu  icu_death  gender  admission_age  weight_admit  \\\n",
       "11  21999692.0     3.05        0.0     1.0      55.139306     52.000000   \n",
       "22  25936663.0     1.15        0.0     1.0      65.032170    189.000000   \n",
       "25  25675339.0     3.16        0.0     1.0      61.837481     95.000000   \n",
       "30  27993048.0     9.02        0.0     0.0      56.881238     78.366667   \n",
       "32  22987108.0    20.53        1.0     1.0      69.439961     86.200000   \n",
       "\n",
       "        height  charlson_score  atrial_fibrillation  malignant_cancer  chf  \\\n",
       "11  172.000000            11.0                  0.0               0.0  0.0   \n",
       "22  185.000000             5.0                  0.0               1.0  0.0   \n",
       "25  159.333333             2.0                  0.0               0.0  0.0   \n",
       "30  168.000000             8.0                  0.0               0.0  1.0   \n",
       "32  185.000000             8.0                  1.0               0.0  0.0   \n",
       "\n",
       "    ckd  cld  copd  diabetes  hypertension  ihd  stroke  \n",
       "11  0.0  0.0   1.0       0.0           0.0  0.0     0.0  \n",
       "22  0.0  1.0   0.0       0.0           1.0  1.0     0.0  \n",
       "25  0.0  0.0   0.0       0.0           0.0  0.0     0.0  \n",
       "30  1.0  0.0   0.0       1.0           1.0  1.0     0.0  \n",
       "32  1.0  0.0   0.0       0.0           1.0  1.0     0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = static.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "static_imputed_numeric = imputer.fit_transform(static[numeric_cols])\n",
    "\n",
    "static[numeric_cols] = static_imputed_numeric\n",
    "\n",
    "static = static[numeric_cols]\n",
    "\n",
    "static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_x = static.drop(['icu_death', 'los_icu'], axis=1)\n",
    "\n",
    "static_y = static['icu_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    static_x,static_y,test_size=0.2,random_state=10,\n",
    "    stratify=static_y, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_1</th>\n",
       "      <th>variable_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [variable_1, variable_2, correlation]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "threshold = 0.9\n",
    "threshold_matrix = correlation_matrix[abs(correlation_matrix) >= threshold]\n",
    "threshold_matrix = threshold_matrix.stack().reset_index().dropna(how='any')\n",
    "\n",
    "threshold_matrix.columns = ['variable_1', 'variable_2', 'correlation']\n",
    "threshold_matrix = threshold_matrix.sort_values(by='correlation', ascending=False)\n",
    "threshold_matrix = threshold_matrix[threshold_matrix.variable_1 != threshold_matrix.variable_2]\n",
    "\n",
    "threshold_matrix['sorted_pair'] = threshold_matrix.apply(lambda row: tuple(sorted([row['variable_1'], \n",
    "                                                                                   row['variable_2']])), \n",
    "                                                         axis=1)\n",
    "\n",
    "threshold_matrix = threshold_matrix.drop_duplicates(subset=['sorted_pair']).drop('sorted_pair', axis=1)\n",
    "\n",
    "threshold_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>height</th>\n",
       "      <th>charlson_score</th>\n",
       "      <th>atrial_fibrillation</th>\n",
       "      <th>malignant_cancer</th>\n",
       "      <th>chf</th>\n",
       "      <th>ckd</th>\n",
       "      <th>cld</th>\n",
       "      <th>copd</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>ihd</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>21201300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.176846</td>\n",
       "      <td>175.1</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>26145609.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.842143</td>\n",
       "      <td>96.5</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>20545926.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.588663</td>\n",
       "      <td>61.7</td>\n",
       "      <td>185.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11280</th>\n",
       "      <td>24761294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.921687</td>\n",
       "      <td>64.7</td>\n",
       "      <td>163.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>24842483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.894356</td>\n",
       "      <td>45.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  gender  admission_age  weight_admit  height  \\\n",
       "15505  21201300.0     1.0      63.176846         175.1   178.0   \n",
       "4115   26145609.0     1.0      66.842143          96.5   170.0   \n",
       "17914  20545926.0     1.0      64.588663          61.7   185.0   \n",
       "11280  24761294.0     0.0      40.921687          64.7   163.0   \n",
       "1340   24842483.0     0.0      89.894356          45.0   152.0   \n",
       "\n",
       "       charlson_score  atrial_fibrillation  malignant_cancer  chf  ckd  cld  \\\n",
       "15505             6.0                  0.0               0.0  0.0  0.0  1.0   \n",
       "4115              5.0                  0.0               1.0  1.0  0.0  0.0   \n",
       "17914             7.0                  1.0               0.0  0.0  1.0  0.0   \n",
       "11280            12.0                  0.0               0.0  0.0  0.0  0.0   \n",
       "1340              5.0                  0.0               0.0  1.0  0.0  0.0   \n",
       "\n",
       "       copd  diabetes  hypertension  ihd  stroke  \n",
       "15505   1.0       0.0           1.0  0.0     0.0  \n",
       "4115    0.0       1.0           1.0  1.0     0.0  \n",
       "17914   0.0       1.0           1.0  0.0     0.0  \n",
       "11280   0.0       0.0           1.0  0.0     0.0  \n",
       "1340    0.0       0.0           1.0  0.0     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICUDeathPredictionDataset(Dataset):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    static: the static DataFrame\n",
    "    notes: the notes DataFrame\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, static, notes, labels):\n",
    "        self.static = static\n",
    "        self.notes = notes\n",
    "        self.labels = labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.static)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        static_X = self.static.iloc[idx]\n",
    "        patient_id = static_X['id']\n",
    "\n",
    "        # notes\n",
    "        notes = self.notes[self.notes['id'] == patient_id].sort_index()['text'].tolist()\n",
    "        notes_X = self.tokenizer(notes, return_tensors='pt', truncation=True, padding='max_length')\n",
    "        patient_timesteps = len(notes)\n",
    "\n",
    "        return static_X, notes_X, patient_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICUDeathPredictionModel(nn.Module):\n",
    "    def __init__(self, static_input_size, out_features=2, hidden_size=256, num_layers=1, batch_first=True):\n",
    "        super(ICUDeathPredictionModel, self).__init__()\n",
    "\n",
    "        self.text_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "\n",
    "        self.lstm = LSTM(input_size=768, hidden_size=hidden_size, num_layers=num_layers, batch_first=batch_first)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=static_input_size + hidden_size),\n",
    "            nn.Linear(in_features=static_input_size + hidden_size, out_features=out_features),\n",
    "            )\n",
    "\n",
    "    def forward(self, static_X_batch, notes_X_batch, patient_timesteps):\n",
    "        embeddings = [self.text_model(**tokenized_notes).pooler_output for tokenized_notes in notes_X_batch]\n",
    "        padded_embeddings = pad_sequence(embeddings, batch_first=True)\n",
    "        packed_embeddings = pack_padded_sequence(input=padded_embeddings, lengths=patient_timesteps, batch_first=True, enforce_sorted=False)\n",
    "        _, (ht, _) = self.time_series_model(packed_embeddings)\n",
    "\n",
    "        ht = ht[-1]\n",
    "\n",
    "        st = torch.tensor(static_X_batch.to_numpy())\n",
    "        combined_representation = torch.cat((ht, st), dim=1)\n",
    "\n",
    "        y_pred = self.fc(combined_representation)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ICUDeathPredictionDataset(static=static_x, notes=notes, labels=static_y)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = ICUDeathPredictionModel(static_input_size=len(static_x.columns))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:719\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 719\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 103 at dim 1 (got 163)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m training_loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     static_X, notes_X, patient_timesteps \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     13\u001b[0m     packed_dynamic_X \u001b[38;5;241m=\u001b[39m packed_dynamic_X\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn [13], line 24\u001b[0m, in \u001b[0;36mICUDeathPredictionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# notes\u001b[39;00m\n\u001b[1;32m     23\u001b[0m notes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m patient_id]\u001b[38;5;241m.\u001b[39msort_index()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 24\u001b[0m notes_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m patient_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(notes)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m static_X, notes_X, patient_timesteps\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2517\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2513\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2514\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2515\u001b[0m         )\n\u001b[1;32m   2516\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2538\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2539\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2556\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2708\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2698\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2699\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2700\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2701\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2705\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2706\u001b[0m )\n\u001b[0;32m-> 2708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2725\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_fast.py:474\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:209\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    205\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:735\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    732\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m             )\n\u001b[0;32m--> 735\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    736\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f'epoch: [{epoch}/{epochs}]')\n",
    "    model.train()\n",
    "    training_loss_epoch = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        static_X, notes_X, patient_timesteps = batch\n",
    "\n",
    "        packed_dynamic_X = packed_dynamic_X.to(device)\n",
    "        los = los.to(device)\n",
    "\n",
    "        notes_X_gpu = []\n",
    "        for notes in notes_X:\n",
    "            notes_gpu = {key: value.to(device) for key, value in notes.items()}\n",
    "            notes_X_gpu.append(notes_gpu)\n",
    "\n",
    "        outputs = model(packed_dynamic_X, notes_X_gpu)\n",
    "\n",
    "        loss = criterion(outputs, los)\n",
    "        training_loss_epoch += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f'step: [{step}/{len(train_loader)}] | loss: {loss.item():.4}')\n",
    "\n",
    "            if step == 0 and epoch == 1:\n",
    "                with open('data/losses/loss_step.txt', 'w') as loss_step_f:\n",
    "                    loss_step_f.write(f'{loss.item():.4f}\\n')\n",
    "\n",
    "            else:\n",
    "                with open('data/losses/loss_step.txt', 'a') as loss_step_f:\n",
    "                    loss_step_f.write(f'{loss.item():.4f}\\n')\n",
    "\n",
    "    avg_training_loss_epoch = training_loss_epoch / len(train_loader)\n",
    "    training_loss.append(avg_training_loss_epoch.item())\n",
    "    print(f'epoch loss: {avg_training_loss_epoch.item():.4f}\\n')\n",
    "\n",
    "    if epoch == 1:\n",
    "        with open('data/losses/loss_epoch.txt', 'w') as loss_epoch_f:\n",
    "            loss_epoch_f.write(f'{avg_training_loss_epoch.item():.4f}\\n')\n",
    "\n",
    "    else:\n",
    "        with open('data/losses/loss_epoch.txt', 'a') as loss_epoch_f:\n",
    "            loss_epoch_f.write(f'{avg_training_loss_epoch.item():.4f}\\n')\n",
    "\n",
    "    print('===============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
